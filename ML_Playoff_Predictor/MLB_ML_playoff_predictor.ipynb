{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playoff Prediction Machine Learning\n",
    "Training a model to predict if an MLB team will make the playoffs or not, as determined by their team level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  franchid                name     city state                        curname  \\\n",
      "0      ANA  Los Angeles Angels  Anaheim    CA  Los Angeles Angels of Anaheim   \n",
      "1      ANA  Los Angeles Angels  Anaheim    CA  Los Angeles Angels of Anaheim   \n",
      "2      ANA  Los Angeles Angels  Anaheim    CA  Los Angeles Angels of Anaheim   \n",
      "3      ANA  Los Angeles Angels  Anaheim    CA  Los Angeles Angels of Anaheim   \n",
      "4      ANA   California Angels  Anaheim    CA  Los Angeles Angels of Anaheim   \n",
      "\n",
      "  lgid  Year    G   w   l  ...  sho  sv ipouts    ha  hra  bba  soa    e   dp  \\\n",
      "0   AL  1961  162  70  91  ...    5  34   4314  1391  180  713  973  192  154   \n",
      "1   AL  1962  162  86  76  ...   15  47   4398  1412  118  616  858  175  153   \n",
      "2   AL  1963  161  70  91  ...   13  31   4365  1317  120  578  889  163  155   \n",
      "3   AL  1964  162  82  80  ...   28  41   4350  1273  100  530  965  138  168   \n",
      "4   AL  1965  162  75  87  ...   14  33   4323  1259   91  563  847  123  149   \n",
      "\n",
      "      fp  \n",
      "0  0.969  \n",
      "1  0.972  \n",
      "2  0.974  \n",
      "3  0.978  \n",
      "4  0.981  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "2192\n",
      "Index(['franchid', 'name', 'city', 'state', 'curname', 'lgid', 'Year', 'G',\n",
      "       'w', 'l', 'postseason', 'divwin', 'wcwin', 'lgwin', 'wswin', 'r', 'ab',\n",
      "       'h', '2B', '3B', 'hr', 'bb', 'so', 'sb', 'cs', 'hbp', 'sf', 'ra', 'er',\n",
      "       'era', 'cg', 'sho', 'sv', 'ipouts', 'ha', 'hra', 'bba', 'soa', 'e',\n",
      "       'dp', 'fp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in csv to pandas\n",
    "team_df = pd.read_csv('../assets/data/mlb_stats.csv')\n",
    "print(team_df.head())\n",
    "print(len(team_df))\n",
    "print(team_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create runs per game and runs allowed per game from r, ra, and G\n",
    "team_df['rpg'] = team_df['r'] / team_df['G']\n",
    "team_df['rapg'] = team_df['ra'] / team_df['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'Year', 'postseason', 'ab', 'h', '2B', '3B', 'hr', 'bb', 'so',\n",
      "       'sb', 'cs', 'hbp', 'sf', 'er', 'era', 'cg', 'sho', 'sv', 'ipouts', 'ha',\n",
      "       'hra', 'bba', 'soa', 'e', 'dp', 'fp', 'rpg', 'rapg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary/unwanted columns\n",
    "\n",
    "dropped_columns = ['w', 'franchid', 'city', 'state', 'curname', 'lgid', 'G', 'l'\n",
    "                   , 'divwin', 'wcwin', 'lgwin', 'wswin', 'r', 'ra']\n",
    "df = team_df.drop(dropped_columns, axis=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See surface level correlation between postseason and other statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 200, 838, 838, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Find null values\n",
    "print(df.isnull().sum(axis=0).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values are in caught stealing, hit by pitch, sac flies.  We can delete caught stealing altogether, as it is not an overly important metric.  However, we need to keep hbp and sf in order to create OBP and OPS metrics down the line, so we will need to fill the null values.  We will impute the missing data by using the median value of the column in question.  While this will not account for changes in playstyle throughout the era, our model already was not going to account for it, so this should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete caught stealing from dataframe\n",
    "\n",
    "df.drop('cs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in hbp and sf\n",
    "\n",
    "df['hbp'] = df['hbp'].fillna(df['hbp'].median())\n",
    "df['sf'] = df['sf'].fillna(df['sf'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training (Base Stats)\n",
    "The first time, we will train the model using the numerical columns we were given (with null values imputed) and no further feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base dataframe for modeling that drops team name and Year\n",
    "\n",
    "base_df = df.drop(['name', 'Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2192, 25) (2192,)\n"
     ]
    }
   ],
   "source": [
    "base_X = base_df.drop(\"postseason\", axis = 1)\n",
    "base_Y = base_df[\"postseason\"]\n",
    "\n",
    "print(base_X.shape, base_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_X_train, base_X_test, base_Y_train, base_Y_test = train_test_split(\n",
    "    base_X, base_Y, random_state=1, stratify=base_Y)\n",
    "\n",
    "base_X_scaler = StandardScaler().fit(base_X_train)\n",
    "base_X_train_scaled = base_X_scaler.transform(base_X_train)\n",
    "base_X_test_scaled = base_X_scaler.transform(base_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded labels to one-hot-encoding\n",
    "\n",
    "base_Y_train_categorical = to_categorical(base_Y_train)\n",
    "base_Y_test_categorical = to_categorical(base_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(Dense(units=100, activation='relu', input_dim=25))\n",
    "base_model.add(Dense(units=100, activation='relu'))\n",
    "base_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 0s - loss: 0.4050 - accuracy: 0.8273\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.2644 - accuracy: 0.8887\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.2444 - accuracy: 0.8990\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.2227 - accuracy: 0.9039\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.2181 - accuracy: 0.9075\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.2064 - accuracy: 0.9106\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.1968 - accuracy: 0.9167\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.1914 - accuracy: 0.9179\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.1795 - accuracy: 0.9270\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.1753 - accuracy: 0.9270\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.1655 - accuracy: 0.9337\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.1605 - accuracy: 0.9380\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.1547 - accuracy: 0.9373\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.1471 - accuracy: 0.9410\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.1451 - accuracy: 0.9367\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.1357 - accuracy: 0.9440\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.1260 - accuracy: 0.9483\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.1204 - accuracy: 0.9489\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.1177 - accuracy: 0.9507\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.1125 - accuracy: 0.9513\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.1019 - accuracy: 0.9623\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.0957 - accuracy: 0.9665\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.0934 - accuracy: 0.9641\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.0839 - accuracy: 0.9708\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.0836 - accuracy: 0.9708\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.0777 - accuracy: 0.9732\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.0744 - accuracy: 0.9745\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.0780 - accuracy: 0.9708\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.0655 - accuracy: 0.9824\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.0583 - accuracy: 0.9818\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.0525 - accuracy: 0.9872\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.0509 - accuracy: 0.9891\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.0513 - accuracy: 0.9872\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.0555 - accuracy: 0.9824\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.0471 - accuracy: 0.9884\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.0364 - accuracy: 0.9945\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.0316 - accuracy: 0.9964\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.0286 - accuracy: 0.9951\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.0287 - accuracy: 0.9957\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.0281 - accuracy: 0.9951\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.0254 - accuracy: 0.9951\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.0222 - accuracy: 0.9982\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.0174 - accuracy: 0.9988\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.0206 - accuracy: 0.9976\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.0173 - accuracy: 0.9982\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.0157 - accuracy: 0.9994\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.0156 - accuracy: 0.9994\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.0115 - accuracy: 0.9994\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.0154 - accuracy: 0.9964\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.0174 - accuracy: 0.9957\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.0102 - accuracy: 0.9994\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 9.9917e-04 - accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 9.7663e-04 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 9.2864e-04 - accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 8.8978e-04 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 8.5055e-04 - accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 8.0226e-04 - accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 7.7760e-04 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 7.5794e-04 - accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 7.1765e-04 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 7.3485e-04 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 6.5280e-04 - accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 6.6548e-04 - accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 5.9254e-04 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 6.1182e-04 - accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 5.7075e-04 - accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 5.2601e-04 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 5.0769e-04 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 4.9038e-04 - accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 4.7612e-04 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 4.5613e-04 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 4.4321e-04 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 4.4066e-04 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 4.1119e-04 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 3.8434e-04 - accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 3.7267e-04 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 3.7167e-04 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 3.4465e-04 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 3.3618e-04 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 3.1278e-04 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 3.1279e-04 - accuracy: 1.0000\n",
      "Epoch 00118: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19ff6819c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "base_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "base_model.fit(\n",
    "    base_X_train_scaled,\n",
    "    base_Y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[EarlyStopping(monitor='accuracy', patience=75, verbose=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Normal Neural Network - Loss: 0.9016347971275775, Accuracy: 0.8759124279022217\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using test data split\n",
    "base_model_loss, base_model_accuracy = base_model.evaluate(\n",
    "    base_X_test_scaled, base_Y_test_categorical, verbose=2)\n",
    "\n",
    "print(\n",
    "    f\"Base Normal Neural Network - Loss: {base_model_loss}, Accuracy: {base_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_encoded_predictions = base_model.predict_classes(base_X_test_scaled[:25])\n",
    "# base_prediction_labels = base_label_encoder.inverse_transform(base_encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Predicted classes: [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Base Actual Labels:     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Base Predicted classes: {list(base_prediction_labels)}\")\n",
    "print(f\"Base Predicted classes: {list(base_encoded_predictions)}\")\n",
    "print(f\"Base Actual Labels:     {list(base_Y_test[:25])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_df_table = pd.DataFrame(base_prediction_labels, columns=['Predicted'])\n",
    "base_df_table = pd.DataFrame(base_encoded_predictions, columns=['Predicted'])\n",
    "base_df_table.insert(loc=1, column='Actual', value= list(base_Y_test[:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           0       0\n",
       "1           0       0\n",
       "2           0       0\n",
       "3           0       0\n",
       "4           1       0\n",
       "5           0       0\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           1       0\n",
       "10          0       0\n",
       "11          0       0\n",
       "12          0       0\n",
       "13          1       1\n",
       "14          0       0\n",
       "15          0       0\n",
       "16          0       0\n",
       "17          0       0\n",
       "18          0       0\n",
       "19          0       0\n",
       "20          0       0\n",
       "21          0       1\n",
       "22          0       0\n",
       "23          0       0\n",
       "24          0       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training (Advanced Stats)\n",
    "This time we will create columns for more advanced statistics and run the model again using those.  Each of these advanced statistics are normalized in some way (by number of games for rundif, at bats for ave and slugging percentage, plate appearances for OBP, and innings pitched for WHIP).\n",
    "Ideally, these normalizations will allow the model to be evaluated at any point in the season, not just at at the end of a season when we already know who makes the postseason.\n",
    "\n",
    "While there are many other advanced statistics that are thought to be better indicators of team/player performance, these are not able to be calculated with the statistics we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for advanced statistics (OBS, OPS, WHIP) as well as run differential and batting average\n",
    "# For plate appearances, we don't have sacrifice hits, so only using sac flies will have to suffice\n",
    "\n",
    "# Run Differential per game\n",
    "df['rundif'] = df['rpg'] - df['rapg']\n",
    "\n",
    "# Batting Average\n",
    "df['ave'] = df['h'] / df['ab']\n",
    "\n",
    "# On Base Percent (OBP) = (hits + walks + hbp)/plate appearances\n",
    "plate_app = (df['ab'] + df['bb'] + df['sf'] +df['hbp'])\n",
    "df['obp'] = (df['h'] + df['bb'] + df['hbp']) / plate_app\n",
    "\n",
    "# Slugging Percent\n",
    "singles = ((df['h'] - df['2B']) - df['3B']) - df['hr']\n",
    "df['slug_percent'] = ((df['hr']*4) + (df['3B']*3) + (df['2B']*2) + singles) / df['ab']\n",
    "\n",
    "# On Base plus Slugging (OPS)\n",
    "df['ops'] = df['obp'] + df['slug_percent']\n",
    "\n",
    "# Walks plus Hits per Inning Pitched (whip)\n",
    "df['whip'] = (df['bba'] + df['ha']) / (df['ipouts']/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'Year', 'postseason', 'ab', 'h', '2B', '3B', 'hr', 'bb', 'so',\n",
       "       'sb', 'hbp', 'sf', 'er', 'era', 'cg', 'sho', 'sv', 'ipouts', 'ha',\n",
       "       'hra', 'bba', 'soa', 'e', 'dp', 'fp', 'rpg', 'rapg', 'rundif', 'ave',\n",
       "       'obp', 'slug_percent', 'ops', 'whip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = df.drop(['rpg', 'ab', 'h', '2B', '3B', 'hr', \n",
    "                  'bb', 'so', 'sb', 'hbp', 'sf', 'rapg', 'er', 'era',\n",
    "                  'cg', 'sho', 'sv', 'ipouts', 'ha', 'hra', 'bba', 'soa', 'e', 'dp', 'fp',\n",
    "                  'ave','obp', 'slug_percent'\n",
    "                 ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Year</th>\n",
       "      <th>postseason</th>\n",
       "      <th>rundif</th>\n",
       "      <th>ops</th>\n",
       "      <th>whip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808642</td>\n",
       "      <td>0.713987</td>\n",
       "      <td>1.157978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.723559</td>\n",
       "      <td>1.205855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.751397</td>\n",
       "      <td>1.192053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.781506</td>\n",
       "      <td>1.240783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.753405</td>\n",
       "      <td>1.249654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name  Year  postseason    rundif       ops      whip\n",
       "2187  Washington Nationals  2014           1  0.808642  0.713987  1.157978\n",
       "2188  Washington Nationals  2015           0  0.419753  0.723559  1.205855\n",
       "2189  Washington Nationals  2016           1  0.932099  0.751397  1.192053\n",
       "2190  Washington Nationals  2017           1  0.907407  0.781506  1.240783\n",
       "2191  Washington Nationals  2018           0  0.549383  0.753405  1.249654"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the 2018 season from adv_df and make a new df_2018\n",
    "\n",
    "df_2018 = adv_df[adv_df['Year'] == 2018]\n",
    "adv_df = adv_df[adv_df['Year'] != 2018]\n",
    "\n",
    "# Delete Year and Team from adv_df\n",
    "\n",
    "adv_df.drop(['name', 'Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2162, 3) (2162,)\n"
     ]
    }
   ],
   "source": [
    "adv_X = adv_df.drop(\"postseason\", axis = 1)\n",
    "adv_Y = adv_df[\"postseason\"]\n",
    "\n",
    "print(adv_X.shape, adv_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_X_train, adv_X_test, adv_Y_train, adv_Y_test = train_test_split(\n",
    "    adv_X, adv_Y, random_state=1, stratify=adv_Y)\n",
    "\n",
    "adv_X_scaler = StandardScaler().fit(adv_X_train)\n",
    "adv_X_train_scaled = adv_X_scaler.transform(adv_X_train)\n",
    "adv_X_test_scaled = adv_X_scaler.transform(adv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded labels to one-hot-encoding\n",
    "adv_Y_train_categorical = to_categorical(adv_Y_train)\n",
    "adv_Y_test_categorical = to_categorical(adv_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "\n",
    "adv_model = Sequential()\n",
    "adv_model.add(Dense(units=100, activation='relu', input_dim=3))\n",
    "adv_model.add(Dense(units=100, activation='relu'))\n",
    "adv_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19ff7fe79b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "\n",
    "adv_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "adv_model.fit(\n",
    "    adv_X_train_scaled,\n",
    "    adv_Y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    callbacks=[EarlyStopping(monitor='accuracy', patience=75, verbose=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Stats Normal Neural Network - Loss: 1.0895163140874253, Accuracy: 0.8336414098739624\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using test data split\n",
    "\n",
    "adv_model_loss, adv_model_accuracy = adv_model.evaluate(\n",
    "    adv_X_test_scaled, adv_Y_test_categorical, verbose=2)\n",
    "\n",
    "print(\n",
    "    f\"Advanced Stats Normal Neural Network - Loss: {adv_model_loss}, Accuracy: {adv_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_encoded_predictions = adv_model.predict_classes(adv_X_test_scaled[:25])\n",
    "# adv_prediction_labels = adv_label_encoder.inverse_transform(adv_encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Stats Predicted classes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "Advanced Stats Actual Labels:     [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Advanced Stats Predicted classes: {list(adv_prediction_labels)}\")\n",
    "print(f\"Advanced Stats Predicted classes: {list(adv_encoded_predictions)}\")\n",
    "print(f\"Advanced Stats Actual Labels:     {list(adv_Y_test[:25])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_df_table = pd.DataFrame(adv_prediction_labels, columns=['Predicted'])\n",
    "adv_df_table = pd.DataFrame(adv_encoded_predictions, columns=['Predicted'])\n",
    "adv_df_table.insert(loc=1, column='Actual', value= list(adv_Y_test[:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           0       1\n",
       "1           0       0\n",
       "2           0       0\n",
       "3           0       0\n",
       "4           0       1\n",
       "5           0       0\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           0       0\n",
       "10          0       0\n",
       "11          1       0\n",
       "12          0       0\n",
       "13          1       0\n",
       "14          0       1\n",
       "15          0       0\n",
       "16          1       1\n",
       "17          0       0\n",
       "18          0       0\n",
       "19          0       1\n",
       "20          1       0\n",
       "21          1       1\n",
       "22          0       0\n",
       "23          0       0\n",
       "24          0       0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Stats Normal Neural Network - Loss 0.9016347971275775, Accuracy: 0.8759124279022217\n",
      "Advanced Stats Normal Neural Network - Loss: 1.0895163140874253, Accuracy: 0.8336414098739624\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Stats Normal Neural Network - Loss {base_model_loss}, Accuracy: {base_model_accuracy}')\n",
    "print(f\"Advanced Stats Normal Neural Network - Loss: {adv_model_loss}, Accuracy: {adv_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Test Case\n",
    "Using the data from the 2018 season that we stripped from adv_df to evaluate our model.  We will then join our newly made predicted/actual table df with our df_2018 to show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3) (30,)\n"
     ]
    }
   ],
   "source": [
    "# Create Test 2018 dataframe\n",
    "\n",
    "test_df_2018 = df_2018.drop(['name', 'Year'], axis=1)\n",
    "\n",
    "# Ready Test 2018 dataframe for predicting\n",
    "\n",
    "X_2018 = test_df_2018.drop('postseason', axis = 1)\n",
    "Y_2018 = test_df_2018['postseason']\n",
    "\n",
    "print(X_2018.shape, Y_2018.shape)\n",
    "\n",
    "# Scale X data\n",
    "\n",
    "X_2018_scaled = StandardScaler().fit(X_2018).transform(X_2018)\n",
    "\n",
    "# One-Hot-Encoding\n",
    "\n",
    "Y_2018_categorical = to_categorical(Y_2018) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions_2018 = adv_model.predict_classes(X_2018_scaled[:30])\n",
    "# prediction_labels_2018 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_table = pd.DataFrame(encoded_predictions_2018, columns=['Predicted'])\n",
    "df_2018_table.insert(loc=1, column='Actual', value=list(Y_2018[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df_2018['name'].tolist()\n",
    "\n",
    "df_2018_table.insert(0, 'Team', names)\n",
    "df_2018_table['Year'] = 2018\n",
    "df_2018_table.set_index('Year', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of 2018 Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Los Angeles Angels of Anaheim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Atlanta Braves</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Chicago Cubs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Chicago White Sox</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Cincinnati Reds</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Cleveland Indians</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Miami Marlins</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Kansas City Royals</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Milwaukee Brewers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Minnesota Twins</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>New York Mets</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Oakland Athletics</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Philadelphia Phillies</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Pittsburgh Pirates</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>San Diego Padres</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Seattle Mariners</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>St. Louis Cardinals</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Tampa Bay Rays</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Texas Rangers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Toronto Blue Jays</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Team  Predicted  Actual\n",
       "Year                                                  \n",
       "2018  Los Angeles Angels of Anaheim          0       0\n",
       "2018           Arizona Diamondbacks          0       0\n",
       "2018                 Atlanta Braves          0       1\n",
       "2018              Baltimore Orioles          0       0\n",
       "2018                 Boston Red Sox          1       1\n",
       "2018                   Chicago Cubs          0       1\n",
       "2018              Chicago White Sox          0       0\n",
       "2018                Cincinnati Reds          0       0\n",
       "2018              Cleveland Indians          1       1\n",
       "2018               Colorado Rockies          1       1\n",
       "2018                 Detroit Tigers          0       0\n",
       "2018                  Miami Marlins          0       0\n",
       "2018                 Houston Astros          1       1\n",
       "2018             Kansas City Royals          0       0\n",
       "2018            Los Angeles Dodgers          1       1\n",
       "2018              Milwaukee Brewers          0       1\n",
       "2018                Minnesota Twins          0       0\n",
       "2018                  New York Mets          0       0\n",
       "2018               New York Yankees          0       1\n",
       "2018              Oakland Athletics          1       1\n",
       "2018          Philadelphia Phillies          0       0\n",
       "2018             Pittsburgh Pirates          0       0\n",
       "2018               San Diego Padres          0       0\n",
       "2018               Seattle Mariners          1       0\n",
       "2018           San Francisco Giants          0       0\n",
       "2018            St. Louis Cardinals          0       0\n",
       "2018                 Tampa Bay Rays          1       0\n",
       "2018                  Texas Rangers          0       0\n",
       "2018              Toronto Blue Jays          0       0\n",
       "2018           Washington Nationals          0       0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model correctly predicted that the Red Sox, Indians, Rockies, Astros, Dodgers, and the A's made the 2018 postseason.\n",
    "\n",
    "It also falsely predicted that the Mariners and Rays would make the postseason when they didn't, and also that the Braves, Cubs, Brewers, and Yankees would miss the postseason when they in fact made it.\n",
    "\n",
    "On this run, our model predicted: 6 true positives, 2 false positives, and 4 false negatives.\n",
    "\n",
    "We classify this as a massive success, because a model that predicts that the Yankees will miss the playoffs is a model worth trusting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda [PythonData]",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
